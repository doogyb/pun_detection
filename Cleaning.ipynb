{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data_processing import load_data\n",
    "import itertools\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ngrams import *\n",
    "from src.string_similarity import levenshtein\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1, task2, task3, min_pairs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['An', 'optometrist', 'told', 'his', 'patient', ':', '\"', 'It', 'appears', 'your', 'vision', 'is', 'improving', '!', '\"', '\"', 'Really', '?', '\"', 'replied', 'the', 'patient', '.', '\"', 'Must', 'be', 'the', 'luck', 'of', 'the', 'iris', '\"', \"'\"], 'pun': True}\n",
      "{'words': ['After', 'being', 'treated', 'by', 'an', 'optometrist', ',', 'the', 'bird', 'seed', '.'], 'pun': True}\n"
     ]
    }
   ],
   "source": [
    "for t in task1:\n",
    "    if \"optometrist\" in t['words']:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(context):\n",
    "    checking = False\n",
    "    res = []\n",
    "    for i in range(len(context)):\n",
    "        if context[i] == \"'\" and not checking:\n",
    "            checking=True\n",
    "            continue\n",
    "        if checking:\n",
    "            if context[i] == \"'\":\n",
    "                res.append('\"')\n",
    "            else:\n",
    "                res.append(\"'\" + context[i])\n",
    "            checking=False\n",
    "        else:\n",
    "            res.append(context[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'halfway',\n",
       " 'up',\n",
       " 'a',\n",
       " 'mountain',\n",
       " ',',\n",
       " '\"',\n",
       " 'Tom',\n",
       " 'alleged',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(task1[0]['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = task1[0]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/contractions.json\") as f:\n",
    "    contractions = set(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "I'\n",
      "halfwayup\n",
      "upa\n",
      "amountain\n",
      "mountain,\n",
      ",'\n",
      "''\n",
      "Tomalleged\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"', \"I'm\", 'halfway', 'up', 'a', 'mountain', ',', '\"', 'Tom']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(test, contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/contractions.json\", 'w') as f:\n",
    "    json.dump([c.split('\\t')[0] for c in contractions.split(\"\\n\")], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
