{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.data_processing import load_data\n",
    "from src.pronunciations import get_closest_sounding_words\n",
    "from nltk import word_tokenize, pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ngram_frequencies.json\") as f:\n",
    "    ngram_frequencies = json.load(f)\n",
    "    \n",
    "task1, task2, task3, min_pairs, pun_strings, strings = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_toms = []\n",
    "task1_no_toms = []\n",
    "for i, context in enumerate(ngram_frequencies):\n",
    "    tom = False\n",
    "    for trigram in [n[0] for n in context]:\n",
    "        if 'Tom' in trigram:\n",
    "            tom = True\n",
    "            break\n",
    "    if not tom:\n",
    "        no_toms.append(context)\n",
    "        task1_no_toms.append(task1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_toms[0], task1_no_toms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_of_trigram(context, trigram):\n",
    "    text = word_tokenize(' '.join(context['words']))\n",
    "    pos_text = pos_tag(text, tagset='universal')\n",
    "    target_pos = pos_text[text.index(trigram[1])][1]\n",
    "    \n",
    "    return target_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a context, look at all trigrams with frequency less than thresh, find similar sounding words.\n",
    "normal_pos = {'ADJ', 'ADV', 'NOUN', 'VERB'}\n",
    "def score(index, threshold=0):\n",
    "    frequencies, context = ngram_frequencies[index], task1[index]\n",
    "    print(frequencies)\n",
    "    for trigram, freq in frequencies:\n",
    "        if freq <= threshold and pos_of_trigram(context, trigram) in normal_pos:\n",
    "            print(trigram)\n",
    "            print(pos_of_trigram(context, trigram))\n",
    "            print(get_closest_sounding_words(trigram[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(6, 10000)\n",
    "# task2[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_closest_sounding_words('harried', share_first_letter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('/home/doogy/Data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('hello', 'goodbye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "from src.pronunciations import phonetic_translation\n",
    "from src.data_processing import load_cmu\n",
    "from collections import defaultdict\n",
    "cmu = load_cmu()\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "def prefixes(word, threshold=None):\n",
    "    \n",
    "    if not threshold:\n",
    "        stem = stemmer.stem(word)\n",
    "        translation = phonetic_translation(stem)\n",
    "        if stem in cmu:\n",
    "            threshold = len(translation)\n",
    "        else:\n",
    "            threshold = len(translation) - 1\n",
    "    \n",
    "    print(threshold)\n",
    "    ret = defaultdict(list)\n",
    "    phonetics = phonetic_translation(word)\n",
    "    seen = {word}\n",
    "    \n",
    "    for i in range(1, len(phonetics)):\n",
    "        for k, v in cmu.items():\n",
    "            if phonetics[:i] == v[0][:i] and k not in seen:\n",
    "                if i >= threshold:\n",
    "                    ret[i].append(k)\n",
    "                    seen.add(k)\n",
    "                # case for when perfect prefixes\n",
    "                    \n",
    "                elif len(v[0]) == i and k not in seen:\n",
    "                    ret[i].append(k)\n",
    "                    seen.add(k)\n",
    "    seen.remove(word)\n",
    "    return ret, seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(list, {2: ['saw'], 3: ['sauce', 'soss'], 4: ['sausages']}),\n",
       " {'sauce', 'sausages', 'saw', 'soss'})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes('saucily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['S', 'AO', 'S', 'IY']], 'saucy')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu['saucy'], stemmer.stem('saucily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whined = prefixes('whined')\n",
    "whined = whined[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def word_sentence_similarity(word, sentence, tokenize=False):\n",
    "    if word not in model.vocab:\n",
    "        return None, -1\n",
    "    \n",
    "    if tokenize:\n",
    "        sentence = word_tokenize(sentence)\n",
    "    max_score = -1\n",
    "    max_pair = None\n",
    "    for w in sentence:\n",
    "        if w in model.vocab:\n",
    "            score = model.similarity(word, w)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_pair = (word, w)\n",
    "    return max_pair, max_score\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "def is_Tom_Swifty(sentence):\n",
    "    # do all the adverb stuff...\n",
    "    # tom swifty has format [PROPER NOUN said ADVERB .]\n",
    "    sentence = word_tokenize(sentence)\n",
    "    pos = pos_tag(sentence)\n",
    "    words = [p[0] for p in pos]\n",
    "    tags = [p[1] for p in pos]\n",
    "    \n",
    "    if 'NNP' not in tags[-5:]:\n",
    "        return False\n",
    "    \n",
    "    for i in range(len(tags)-1, 0, -1):\n",
    "        if tags[i] == 'NNP':\n",
    "            noun_position = i\n",
    "            break\n",
    "        \n",
    "    candidates = []\n",
    "    for i in range(noun_position+1, len(tags)):\n",
    "        if tags[i] in {'VBD', 'RB'}:\n",
    "            candidates.append(words[i])\n",
    "    \n",
    "    # If the word is neither an adverb or verb, return false\n",
    "    if len(candidates) == 0:\n",
    "        return False\n",
    "\n",
    "    prefs = []\n",
    "    for candidate in candidates:\n",
    "        a, b = prefixes(candidate, 3)\n",
    "        prefs.extend(b)\n",
    "    \n",
    "    # get utterance\n",
    "    for i in range(len(pos)):\n",
    "        pass\n",
    "        \n",
    "    # remove stopwords and search word\n",
    "    \n",
    "    search_sentence = [w for w in sentence if w.lower() not in stopwords.words('english') and w not in candidates]\n",
    "    \n",
    "    max_score = -1\n",
    "    best_pair = None\n",
    "    for word in prefs:\n",
    "        pair, score = word_sentence_similarity(word, search_sentence)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_pair = pair\n",
    "    return best_pair, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('sauce', 'pizza'), 0.36959888341468228)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sentence_similarity('sauce', '\"This pizza place is great!\" Tom exclaimed saucily.', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('sheep', 'lambs'), 0.71513635423071409)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_Tom_Swifty(\"'How many lambs are on your farm?' Tom asked sheepishly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'punct'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('punctually')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sauce' in prefixes('saucily')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['G', 'R', 'EY', 'T', 'IH', 'NG', 'L', 'IY'], 'grat')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonetic_translation('gratingly'), stemmer.stem('gratingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu['bluntly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sheep'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('sheepishly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lstemmer = LancasterStemmer()\n",
    "lstemmer.stem('bluntly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'civilly',\n",
       " 'haughtily',\n",
       " 'icily',\n",
       " 'saucy',\n",
       " 'sawmill',\n",
       " 'sawmills',\n",
       " 'sicily',\n",
       " 'silly',\n",
       " 'softly',\n",
       " 'sorely'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_sounding_words('saucily')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
