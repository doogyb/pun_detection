{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Loading Model, this could take a while...\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import load_data\n",
    "import itertools\n",
    "import string\n",
    "from src.pun_algorithms import *\n",
    "from src.ngrams import *\n",
    "from src.string_similarity import levenshtein\n",
    "import operator\n",
    "from src.data_processing import print_progress\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from src.data_processing import load_cmu\n",
    "from src.ipatoarpabet import translate\n",
    "from string import punctuation\n",
    "from src.pronunciations import phonetic_distance\n",
    "import os\n",
    "from pattern.en import lexeme\n",
    "from src.pronunciations import get_closest_sounding_words as csw\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1, task2, task3, min_pairs, strings, pun_strings = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ngram_searchspace/task1_totals.json\") as f:\n",
    "    search_space = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(run):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(len(task1)):\n",
    "        gold_pun = task1[i]['pun']\n",
    "        if run[i] and gold_pun:\n",
    "            tp += 1\n",
    "        if not run[i] and not gold_pun:\n",
    "            tn += 1\n",
    "        if run[i] and not gold_pun:\n",
    "            fp += 1\n",
    "        if not run[i] and gold_pun:\n",
    "            fn += 1\n",
    "    \n",
    "    results = {}\n",
    "    results['acc'] = (tp + tn) / len(task1)\n",
    "    results['recall'] = tp / (tp + fn)\n",
    "    results['prec'] = tp / (tp + fp)\n",
    "    results['f1'] = ((2*(results['recall'] * results['prec']))\n",
    "                      / (results['recall'] + results['prec']))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Trigram Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_trigram_baseline(index):\n",
    "    current_context = search_space[index]\n",
    "    for original_trigram in current_context:\n",
    "        if current_context[original_trigram]['original_frequency'] == 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [no_trigram_baseline(index) for index in range(len(search_space))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7825842696629214,\n",
       " 'f1': 0.8457552809884415,\n",
       " 'prec': 0.8570274636510501,\n",
       " 'recall': 0.8347757671125098}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_accuracy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Quadgram Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quadgrams_in_task1 = set()\n",
    "for context in task1:\n",
    "    words = context['words']\n",
    "    for i in range(len(words)-3):\n",
    "        all_quadgrams_in_task1.add(' '.join(words[i:i+4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quadgrams_in_task1 = list(sorted(all_quadgrams_in_task1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = defaultdict(list)\n",
    "for quadgram in all_quadgrams_in_task1:\n",
    "    groupings[quadgram.split()[0][:3]].append(quadgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad_to_dict(text):\n",
    "    ret = {}\n",
    "    for line in text.split('\\n'):\n",
    "        lsplit = line.split()\n",
    "        try:\n",
    "            ret[' '.join(lsplit[:4])] = int(lsplit[4])\n",
    "        except:\n",
    "            pass\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 99.9% "
     ]
    }
   ],
   "source": [
    "quadgram_frequencies ={}\n",
    "for i, beginning_letters in enumerate(groupings):\n",
    "    try:\n",
    "        ngram_output = subprocess.check_output(['zcat', get_gram_file(beginning_letters, 4)]).decode('latin-1')\n",
    "    except:\n",
    "        pass\n",
    "    quad_dict = quad_to_dict(ngram_output)\n",
    "    for subquads in groupings[beginning_letters]:\n",
    "        try:\n",
    "#             print(subquads)\n",
    "            quadgram_frequencies[subquads] = quad_dict[subquads]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    print_progress(i, len(groupings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/quadgram_frequencies.json\") as f:\n",
    "    quadgram_frequencies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_quadgram_baseline(index):\n",
    "    context = task1[index]['words']\n",
    "    for i in range(0, len(context)-3):\n",
    "        if ' '.join(context[i:i+4]) not in quadgram_frequencies:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [no_quadgram_baseline(i) for i in range(len(task1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7893258426966292,\n",
       " 'f1': 0.8700173310225303,\n",
       " 'prec': 0.7775712515489467,\n",
       " 'recall': 0.987411487018096}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_accuracy(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
