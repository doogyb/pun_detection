{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.data_processing import print_progress, scores_as_list, load_data, load_cmu\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "from src.pun_algorithms import is_Tom_Swifty\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.KeyedVectors.load_word2vec_format(\"/home/doogy/Data/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1, task2, task3, min_pairs, strings, pun_strings = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 99.9% "
     ]
    }
   ],
   "source": [
    "substitutions = scores_as_list(\"all_trigram_with_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/tom_swifties.json\") as f:\n",
    "    tom_swifty_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/t1-t2-mappings.json\") as f:\n",
    "    mappings = {int(k): int(v) for k, v in json.load(f).items()}\n",
    "\n",
    "t2_subs = []\n",
    "for i, (t1, t2) in enumerate(mappings.items()):\n",
    "    t2_subs.append(list(sorted(substitutions[t2].items(), key=lambda x: x[1][0][1], reverse=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage, Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage:  0.988198269079465\n",
      "Precision:  0.7659235668789809\n",
      "Recall:  0.7568843430369787\n",
      "F1:  0.7613771270280965\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "guesses = 0\n",
    "for i in range(len(task2)):\n",
    "    if tom_swifty_annotations[i]:\n",
    "        tp += int(task2[i]['target'] == tom_swifty_annotations[i][0][0])\n",
    "        guesses += 1\n",
    "    else:\n",
    "        if len(t2_subs) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            tp += int(task2[i]['target'] == t2_subs[i][0][0].split()[1])\n",
    "            guesses += 1\n",
    "        except:\n",
    "            pass\n",
    "print(\"Coverage: \", guesses / len(task2))\n",
    "print(\"Precision: \", tp/guesses)\n",
    "print(\"Recall: \", tp/len(task2))\n",
    "print(\"F1: \", (2 * (tp/guesses) * (tp/len(task2))) / ((tp/guesses) + (tp/len(task2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank:  0.8117099396800422\n"
     ]
    }
   ],
   "source": [
    "total_rank = 0\n",
    "for i in range(len(task2)):\n",
    "    target = task2[i]['target']\n",
    "    \n",
    "    if tom_swifty_annotations[i]:\n",
    "        ranks = [r[0] for r in tom_swifty_annotations[i]]\n",
    "        if target in ranks:\n",
    "            total_rank += 1 / (ranks.index(target) + 1)\n",
    "    else:\n",
    "        try:\n",
    "            ranks = [r[0].split()[1] for r in t2_subs[i]]\n",
    "            if target in ranks:\n",
    "                total_rank += 1 / (ranks.index(target) + 1)\n",
    "        except:\n",
    "            pass   \n",
    "    \n",
    "print(\"Mean Reciprocal Rank: \", total_rank / len(task2))      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
